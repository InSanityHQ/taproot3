<html><head><meta charset="utf-8" /><meta content="width=device-width, initial-scale=1.0" name="viewport" /><meta content="Taproot Authors" name="author" /><meta content="A collection of academic and project notes" name="description" /><title>Taproot</title><link href="/static/css/firn_base.css" rel="stylesheet" /><link href="/static/css/prism.css" rel="stylesheet" /><link href="/static/css/global.css" rel="stylesheet" /><script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/prism.min.js" type="text/javascript"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        'displayAlign': 'center',
        'displayIndent': '0em',
        'extensions': ['tex2jax.js'],
        'tex2jax': {
        'inlineMath': [ ['$','$'], ['\\(','\\)'] ],
        'processEscapes': true
        },
        'HTML-CSS': { scale: 100,
                        linebreaks: { automatic: 'false' },
                        webFont: 'TeX'
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: 'false' },
              font: 'TeX'},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: 'AMS'},
               MultLineWidth: '85%',
               TagSide: 'right',
               TagIndent: '.8em'
             }})</script></head><body><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/components/prism-core.min.js" type="text/javascript"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/plugins/autoloader/prism-autoloader.min.js" type="text/javascript"></script><div class="headerline"><a class="wordmark" href="https://taproot3.sanity.gq/" style="border:0">TR3</a></div><main><article class="content rss"><div class="preamble"><h1 class="title">Ml Corrections Bin</h1></div><div class="metamble"><span><span>Written by </span><span>Huxley</span></span></div><div class="notebody"><div><section><p><span>#ref #ret</span></p><hr /></section><div class="firn-headline-section firn-headline-section-1"><h1 class="firn-headline firn-headline-1" id="corrections!"><span class="firn-headline-text"><span>Corrections!</span></span></h1><div class="firn-headline-section firn-headline-section-2"><h2 class="firn-headline firn-headline-2" id="validation"><span class="firn-headline-text"><span>Validation</span></span></h2><section><p><span>org: </span><a class="firn-internal" href="/cs/intro_to_ml/KBValidationPB">KBValidationPB</a></p><p><span>For problem 2c, the least helpful score would be 0.5, in which every
sample is sorted randomly. This would give virtually no information, and
is just as good as random.</span></p><p><span>The 'worst' possible score, however, would still be 0. This is just a
definitions games, as, of course, you could simply flip the results
around and get a perfect score.</span></p><p><span>In actuality we don't really know the probability that a perfect model
will return. Thus, all we can say is that the probability will be >=
50%.</span></p></section></div><div class="firn-headline-section firn-headline-section-2"><h2 class="firn-headline firn-headline-2" id="classification"><span class="firn-headline-text"><span>Classification</span></span></h2><section><p><span>Hi Wes,</span></p><p><span>Each of these notebooks do introduce new concepts to me, so I am
definitely still learning. They just go by pretty quickly. However, I
would love to work on some more projects, especially once we get to the
more advanced topics!</span></p><p><span>#5: Using sepal length and sepal width, the structure is significantly
more complicated. See attached image.</span></p><p><span>As for the random forest and decision tree, if I were to compare them, I
would compare their F1 scores on test data.</span></p><p><span>For Naive Bayes, less obvious words which sway the prediction immensely
include: 'on', 'that', and 'of'.</span></p><p><span>The words 'on', 'that', and 'of' appear much more in sci.space than the
other categories, and tend to sway the prediction towards sci.space
greatly. This does not match my intuition of how the model should work.</span></p><p><span>Thanks for the feedback!</span></p></section></div><div class="firn-headline-section firn-headline-section-2"><h2 class="firn-headline firn-headline-2" id="linear-regression"><span class="firn-headline-text"><span>Linear Regression</span></span></h2><section><p><span>Sorry for the confusion! In the future, I'll submit the direct github
link to the file, or add a comment with all the direct links.</span></p><p><span>Exercises 1-2: I would expect the model to predict numbers according to
the intercept and coefficient that it did find, which, "if the linear
regression code was working," should be close the to function that the
model is trying to fit, right? I think I may be misunderstanding your
question.</span></p><p><span>I don't have a lot of logic behind why I chose to use SVM besides the
fact that it looked interesting and I wanted to figure out how to use
it. I believe that polynomial regression is more prone to overfitting,
but I'm not entirely sure on that.</span></p><p><span>More broadly speaking, to know if my regularization code worked, I could
look for an increase in R^2. This is because a completely over-fitted
model would, by definition, have an R^2 of 0. Generalizing, or
regularizing the model would make the model less specific to the
training data, increasing the R^2.</span></p></section></div></div></div></div></article><div class="metapanel"><div class="metalabel">Contents</div><ol><li><a href="#corrections!">Corrections!</a><ol><li><a href="#validation">Validation</a></li><li><a href="#classification">Classification</a></li><li><a href="#linear-regression">Linear Regression</a></li></ol></li></ol><div class="metalabel">Backlinks</div></div></main></body></html>