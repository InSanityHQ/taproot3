<html><head><meta charset="utf-8" /><meta content="width=device-width, initial-scale=1.0" name="viewport" /><meta content="Huxley" name="author" /><meta content="A note on Taproot, a connected notes system." name="description" /><title>Data Processing Assignment</title><link href="/static/css/firn_base.css" rel="stylesheet" /><link href="/static/css/prism.css" rel="stylesheet" /><link href="/static/css/global.css" rel="stylesheet" /><script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/prism.min.js" type="text/javascript"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        'displayAlign': 'center',
        'displayIndent': '0em',
        'extensions': ['tex2jax.js'],
        'tex2jax': {
        'inlineMath': [ ['$','$'], ['\\(','\\)'] ],
        'processEscapes': true
        },
        'HTML-CSS': { scale: 100,
                        linebreaks: { automatic: 'false' },
                        webFont: 'TeX'
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: 'false' },
              font: 'TeX'},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: 'AMS'},
               MultLineWidth: '85%',
               TagSide: 'right',
               TagIndent: '.8em'
             }})</script></head><body><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/components/prism-core.min.js" type="text/javascript"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/plugins/autoloader/prism-autoloader.min.js" type="text/javascript"></script><div class="headerline"><a class="wordmark" href="https://taproot3.sanity.gq/" style="border:0">TR3</a></div><main><article class="content rss"><div class="preamble"><h1 class="title">Data Processing Assignment</h1></div><div class="metamble"><span><span>Written by </span><span>Huxley</span></span></div><div class="notebody"><div><section><p><span>#ret</span></p><hr /></section><div class="firn-headline-section firn-headline-section-2"><h2 class="firn-headline firn-headline-2" id="prompt:"><span class="firn-headline-text"><span>Prompt:</span></span></h2><section></section></div><div class="firn-headline-section firn-headline-section-2"><h2 class="firn-headline firn-headline-2" id="scenarios:"><span class="firn-headline-text"><span>Scenarios:</span></span></h2><section><ul><li><p><span>Football</span></p><ol><li><p><span>Note: Since we only have one season of point values, and hence
     cannot see cross season change in point values, the old season
     players will be used as training data.</span></p></li><li><p><span>Regression</span></p></li><li><p><span>Label: Point value</span></p></li><li><p><span>One Hot Encoding, 0-1 normalization</span></p></li><li><p><span>Linear Regression or Neural Networks</span></p></li><li><p><span>RMSE</span></p></li><li><p><span>None</span></p></li></ol></li><li><p><span>Customer Reviews</span></p><ol><li><p><span>Classification</span></p></li><li><p><span>Positive, Negative, Neutral</span></p></li><li><p><span>Some form of text processing -- BOW, TFIDF, word vectors, ect.</span></p></li><li><p><span>Out of the models we have learned, Naive Bayes.</span></p></li><li><p><span>F score</span></p></li><li><p><span>Could misrepresent reviews and allow for automation</span></p></li></ol></li><li><p><span>Movie Recommendations</span></p><ol><li><p><span>Classification</span></p></li><li><p><span>Semi-supervised.</span></p></li><li><p><span>One Hot Encoding and BOW or TFIDF</span></p></li><li><p><span>Random forest? NN?</span></p></li><li><p><span>Click rate or watch time, depending on goal.</span></p></li><li><p><span>Ethics crumble in the face of capitalism. We gotta get our clients
     the right recommendations!</span></p></li></ol></li><li><p><span>Facebook Pet</span></p><ol><li><p><span>Classification</span></p></li><li><p><span>Supervised: Dog, Cat, Neither</span></p></li><li><p><span>WPIE type system.</span></p></li><li><p><span>NN</span></p></li><li><p><span>F score\\</span></p></li><li><p><span>Collection of likes is invasive. Categorizing of people is also
     problematic, as is trying to determine private info.</span></p></li></ol></li><li><p><span>Deer Born</span></p><ol><li><p><span>Regression</span></p></li><li><p><span>Supervised: Number of deer</span></p></li><li><p><span>One Hot</span></p></li><li><p><span>Linear regression, NN</span></p></li><li><p><span>RMSE</span></p></li><li><p><span>None</span></p></li></ol></li></ul></section></div><div class="firn-headline-section firn-headline-section-2"><h2 class="firn-headline firn-headline-2" id="comment-response"><span class="firn-headline-text"><span>Comment Response</span></span></h2><section><ul><li><p><span>2b. How do you convert from the 1-10 rating scale to
  positive/negative/neutral?</span></p><ul><li><p><span>You would have to pick ranges that define what is
    positive/negative/neutral</span></p></li></ul></li><li><p><span>2c. Given that the reviews vary greatly in their length, is one of
  these preferred over the other?</span></p><ul><li><p><span>BOW doesn't work well when length varies. TFIDF, however, does.</span></p></li></ul></li><li><p><span>2e. Why not accuracy, precision, or recall?</span></p><ul><li><p><span>Those would all work as well. I just decided to list one possible
    validation metric as opposed to all of them.</span></p></li></ul></li><li><p><span>3a. This could work, but I think you will find this problem more
  straightforward as a different kind of problem.</span></p><ul><li><p><span>I guess this problem could be done as a clustering problem,
    representing each movie as a location in a multidimensional space
    then placing users in the space and clustering.</span></p></li></ul></li><li><p><span>3b. Semi-supervised usually refers to models where we have some
  labels, and we generate additional labels. Where do our labels come
  from? How do we generate the additional ones?</span></p><ul><li><p><span>The original labels would most likely be generated. As time
    progresses, we get labels back from the users that are interacting
    with our model's recommendations.</span></p></li></ul></li><li><p><span>3c. Be more specific: which features would you use which techniques
  on? For example, you could use bag of words or OHE on the names of the
  stars, but you'd get pretty different results depending on which one
  you picked.</span></p><ul><li><p><span>OHE: name of stars, genre. BOW or TFID: title.</span></p></li></ul></li><li><p><span>3e. A user not watching a recommendation is not necessarily good
  signal on whether it's a good recommendation (i.e. I might really like
  a movie, and just not have time to watch it right now). Conversely, a
  user watching a movie is not necessarily signal that it was a good
  recommendation (maybe I watched it because you recommended it, but I
  hated it).</span></p><ul><li><p><span>This depends on the goal of the recommendation. If you get a good
    recommendation and don't watch it, was it really a good
    recommendation? If the goal is simply to increase watch time, and
    thus increase the number of ads viewed, then yes watching or not
    watching is a good metric. Think click-bait. Of course, this has to
    be weighed against the long term effects of the recommendation.</span></p></li></ul></li><li><p><span>3f. I know you are kidding (I hope so, at least!), but the whole point
  of us learning about ethics is precisely so that they do not crumble
  in the face of capitalism!</span></p><ul><li><p><span>I think maybe we should shift the goal to rebuilding the already
    crumbled ethics...</span></p></li></ul></li><li><p><span>4b. Where do these labels come from?</span></p><ul><li><p><span>From the friends you asked.</span></p></li></ul></li><li><p><span>4c/d. Why WPIE/NN? Is there a simpler approach we might try first?</span></p><ul><li><p><span>BOW, TFIDF, or word vectors would work, but Facebook's method itself
    would most likely work better. As for the type of model, Decision
    Trees and Random Forests would work.</span></p></li></ul></li><li><p><span>4e. Why not accuracy, precision, or recall?</span></p><ul><li><p><span>Again, just decided to list one validation metric. Accuracy,
    precision, and recall would also work.</span></p></li></ul></li></ul><p><a class="firn-internal" href="/history/history10/KBdataProsResponses">KBdataProsResponses</a></p></section></div></div></div></article><div class="metapanel"><div class="metalabel">Contents</div><ol><li><a href="#prompt:">Prompt:</a></li><li><a href="#scenarios:">Scenarios:</a></li><li><a href="#comment-response">Comment Response</a></li></ol><div class="metalabel">Backlinks</div><ul class="firn-backlinks"><li class="firn-backlink"><a href="/history/history10/KBdataProsResponses">Data Processing Responses</a></li><li class="firn-backlink"><a href="/history/history10/KBMlMasterIndex">Ml Master Index</a></li></ul></div></main></body></html>