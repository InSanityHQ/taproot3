<html><head><meta charset="utf-8" /><meta content="width=device-width, initial-scale=1.0" name="viewport" /><meta content="Taproot Authors" name="author" /><meta content="A collection of academic and project notes" name="description" /><title>Taproot</title><link href="/static/css/firn_base.css" rel="stylesheet" /><link href="/static/css/prism.css" rel="stylesheet" /><link href="/static/css/global.css" rel="stylesheet" /><script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/prism.min.js" type="text/javascript"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        'displayAlign': 'center',
        'displayIndent': '0em',
        'extensions': ['tex2jax.js'],
        'tex2jax': {
        'inlineMath': [ ['$','$'], ['\\(','\\)'] ],
        'processEscapes': true
        },
        'HTML-CSS': { scale: 100,
                        linebreaks: { automatic: 'false' },
                        webFont: 'TeX'
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: 'false' },
              font: 'TeX'},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: 'AMS'},
               MultLineWidth: '85%',
               TagSide: 'right',
               TagIndent: '.8em'}
tex: {
autoload: {
                cases: [[], ['numcases', 'subnumcases']]
        }
}})</script></head><body><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/components/prism-core.min.js" type="text/javascript"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/plugins/autoloader/prism-autoloader.min.js" type="text/javascript"></script><div class="headerline"><a class="wordmark" href="https://taproot3.sanity.gq/" style="border:0">TR3</a></div><main><article class="content rss"><div class="preamble"><h1 class="title">Questions to Ponder about $A^TA$ and $AA^T$</h1></div><div class="metamble"></div><div class="notebody"><div><section></section><div class="firn-headline-section firn-headline-section-1"><h1 class="firn-headline firn-headline-1" id="a-real-valued-matrix"><span class="firn-headline-text"><span>A real valued matrix</span></span></h1><section><p><span>  Let $A =\begin{pmatrix}2 &1 \\ 3 & 2\end{pmatrix}$
  \[\begin{aligned}
  AA^T &= \begin{pmatrix}2 &1 \\ 3 & 2\end{pmatrix}\begin{pmatrix}2 &3 \\ 1 & 2\end{pmatrix} &=\begin{pmatrix}5 & 8 \\ 8 & 13\end{pmatrix}\\
  A^TA &= \begin{pmatrix}2 &3 \\ 1 & 2\end{pmatrix}\begin{pmatrix}2 &1 \\ 3 & 2\end{pmatrix} &=\begin{pmatrix}13 & 8 \\ 8 & 5\end{pmatrix}\\
  \end{aligned}\]</span></p><p><span>  \[\begin{aligned}
  \begin{pmatrix}a&b\\c&d\end{pmatrix}\begin{pmatrix}a&c\\b&d\end{pmatrix} =\begin{pmatrix}a^2+b^2 & ac+bd \\ ac+bd & c^2+d^2 \end{pmatrix}
  \end{aligned}\]
  Then, $A^TA$ is the same thing, but with $b, c$ swapped.</span></p></section></div><div class="firn-headline-section firn-headline-section-1"><h1 class="firn-headline firn-headline-1" id="for-complex-matrices"><span class="firn-headline-text"><span>For complex matrices</span></span></h1><section><p><span>  \[\begin{aligned}
  \begin{pmatrix}a+bi & c+di \\ f+gi & j+ki\end{pmatrix} \begin{pmatrix}a+bi & f+gi \\ c+di & j+ki\end{pmatrix} =
  \begin{pmatrix}a^2-b^2+2abi + c^2-d^2+2cdi & af + agi + bfi - bg \\ af + agi + bfi - bg & f^2-g^2+2fgi + j^2-k^2+2jki\end{pmatrix}
  \end{aligned}\]</span></p><p><span>  I'm not sure if I'm noticing anything different from the real ones, although maybe the variables are just too confusing.</span></p></section></div><div class="firn-headline-section firn-headline-section-1"><h1 class="firn-headline firn-headline-1" id="complex-conjugate-($a^*a$-vs-$a-a^*$)"><span class="firn-headline-text"><span>Complex conjugate ($A^*A$ vs $A A^*$)</span></span></h1><section><p><span>  \[\begin{aligned}
  \begin{pmatrix}a+bi & c+di \\ f+gi & j+ki \end{pmatrix}
  \begin{pmatrix}a-bi & f-gi \\ c-di & j-ki \end{pmatrix} =
  \begin{pmatrix} a^2 + b^2 + c^2 + d^2 & () \\ () & f^2 + g^2 + j^2 + k^2 \end{pmatrix}
  \end{aligned}\]</span></p><p><span>  \[\begin{aligned}
  \begin{pmatrix}a-bi & f-gi \\ c-di & j-ki \end{pmatrix}
  \begin{pmatrix}a+bi & c+di \\ f+gi & j+ki \end{pmatrix} =
  \begin{pmatrix} a^2 + b^2 + f^2 + g^2 & () \\ () & c^2 + d^2 + j^2 + k^2 \end{pmatrix}
  \end{aligned}\]</span></p><p><span>  The diagonals are real-valued, and the matrices are symmetric about the diagonal. I wonder if this means the matrices have identical eigenvalues... how do the diagonals of complex matricies change when they are upper-triangularized?</span></p></section></div><div class="firn-headline-section firn-headline-section-1"><h1 class="firn-headline firn-headline-1" id="transpose-distributivity-with-matrix-multiplication"><span class="firn-headline-text"><span>Transpose distributivity with matrix multiplication</span></span></h1><section><p><span>  \[\begin{aligned}
  (AB)^\top =\left(\begin{pmatrix}a&b\\c&d\end{pmatrix}\begin{pmatrix}w&x\\y&z\end{pmatrix}\right) ^\top
  =\begin{pmatrix}aw+by & cw+dy \\ ax + bz & cx + dz \end{pmatrix} =\begin{pmatrix}w&y\\x&z\end{pmatrix}\begin{pmatrix}a&c\\b&d\end{pmatrix} = B^\top A^\top
  \end{aligned}\]</span></p><p><span>  I have no good proof of this for larger matrices or non-square matrices, but it makes sense because both scalar addition and scalar multiplication are commutative and transposing swaps rows for columns. Thus, when a matrix on the left is multiplied by a matrix on the right, it is the same as the left matrix becoming the right matrix but after a transpose, because both operations swap the rows and columns in some sense so they "cancel out".</span></p></section></div><div class="firn-headline-section firn-headline-section-1"><h1 class="firn-headline firn-headline-1" id="determinant-distributivity-with-matrix-multiplication"><span class="firn-headline-text"><span>Determinant distributivity with matrix multiplication</span></span></h1><section><p><span>  \[\begin{aligned}
  &\left| \begin{pmatrix}aw+by & ax + bz\\ cw + dy & cx + dz\end{pmatrix} \right|   \\
  &= (aw+by)(cx+dz) - (ax+bz)(cw+dy) \\
  &= \cancel{acwx} + adwz + bcxy + \cancel{bdyz} - (\cancel{acwx} + adxy + bcwz + \cancel{bdyz}) \\
  &= adwz - adxy - bcwz + bcxy\\
  &= (ad-bc)(wz-xy) \\
  &= \left|\begin{pmatrix}a&b\\c&d\end{pmatrix}\right|\left|\begin{pmatrix}w&x\\y&z\end{pmatrix}\right|
  \end{aligned}\]</span></p><p><span>  This makes sense given that the determinant of a matrix can be considered a "scaling factor." We had talked about the determinant being the area of the parallelogram of the column vectors, but not about how that represented the matrix multiplied by the identity whose column parallelogram has area one. Thus, the composition should multiply areas, which it seems to do.</span></p><p><span>  This can probably be the base case of an induction proof that extends this to larger matrices, since determinants are defined recursively.</span></p></section></div></div></div></article><div class="metapanel"><div class="metalabel">Contents</div><ol><li><a href="#a-real-valued-matrix">A real valued matrix</a></li><li><a href="#for-complex-matrices">For complex matrices</a></li><li><a href="#complex-conjugate-($a^*a$-vs-$a-a^*$)">Complex conjugate ($A^*A$ vs $A A^*$)</a></li><li><a href="#transpose-distributivity-with-matrix-multiplication">Transpose distributivity with matrix multiplication</a></li><li><a href="#determinant-distributivity-with-matrix-multiplication">Determinant distributivity with matrix multiplication</a></li></ol><div class="metalabel">Backlinks</div></div></main></body></html>