<html><head><meta charset="utf-8" /><meta content="width=device-width, initial-scale=1.0" name="viewport" /><meta name="author" /><meta content="A note on Taproot, a connected notes system." name="description" /><title>Lens Quiz Prep</title><link href="/static/css/firn_base.css" rel="stylesheet" /><link href="/static/css/prism.css" rel="stylesheet" /><link href="/static/css/global.css" rel="stylesheet" /><link href="/static/css/admonition.css" rel="stylesheet" /><script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/prism.min.js" type="text/javascript"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        'displayAlign': 'center',
        'displayIndent': '0em',
        'extensions': ['tex2jax.js'],
        'tex2jax': {
        'inlineMath': [ ['$','$'], ['\\(','\\)'] ],
        'processEscapes': true
        },
        'HTML-CSS': { scale: 100,
                        linebreaks: { automatic: 'false' },
                        webFont: 'TeX'
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: 'false' },
              font: 'TeX'},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: 'AMS'},
               MultLineWidth: '85%',
               TagSide: 'right',
               TagIndent: '.8em'
             }})</script></head><body><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/components/prism-core.min.js" type="text/javascript"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/plugins/autoloader/prism-autoloader.min.js" type="text/javascript"></script><script crossorigin=="anonymous" src="https://kit.fontawesome.com/76c5ce8bda.js"></script><div class="headerline"><a class="wordmark" href="https://taproot3.sanity.gq/" style="border:0">TR3</a></div><main><article class="content rss"><div class="preamble"><h1 class="title">Lens Quiz Prep</h1></div><div class="metamble"></div><div class="notebody"><div><section></section><div class="firn-headline-section firn-headline-section-3"><h3 class="firn-headline firn-headline-3" id="lenses"><span class="firn-headline-text"><a href="#id:2cf94571-b530-44e8-a710-786a27c9b2f6">Lenses</a></span></h3><section><ul><li><p><span>Rays that go in parallel come out through focal point</span></p></li><li><p><span>Rays that go in through focal point come out parallel</span></p></li><li><p><span>Rays that come in through $2f$ comes ou through $2f$</span></p></li><li><p><span>Thin Lens Equation: $\frac{1}{f} = \frac{1}{d_o} + \frac{1}{d_i}$</span></p></li><li><p><span>For a thin lens in air: $\frac{1}{f} = (n-1)\left[ \frac{1}{R_1} - \frac{1}{R_2}\right]$ where $R_1$ and $R_2$ are the radii of curvature for each face of the lens and $n$ the index of refraction of the lens. If $R_1 = R_2$ (like some crescent shape) the light wouldn't focus (or it'd focus at infinity).</span></p></li></ul><p><span>$h_i = -\frac{d_i}{d_o}h_o$</span></p></section></div><div class="firn-headline-section firn-headline-section-3"><h3 class="firn-headline firn-headline-3" id="cameras"><span class="firn-headline-text"><a href="#id:67dabfb5-6f9a-4acd-97ae-a2cf9df0ac24">Cameras</a></span></h3><section><ul><li><p><span>ISO: Range is usually from 100-25600. High ISO: noise (overall signal is lower so noise is higher relative to signal)</span></p></li><li><p><span>Aperture: </span><em><span>f-stop</span></em><span> is the </span><u><span>inverse</span></u><span> of the aperture. Aperture is $f$ over the f-stop. At a f-stop of 2, aperture is $\frac{50\text{mm}}{2} = 25\text{mm}$. Each f-stop lets in twice as much light as the previous.</span></p></li><li><p><span>Shutter speed: Longer exposure lets more light hit the sensor. Higher exposure can capture more movement and vice versa. You can handhold 1/focal length and still get a sharp picture.</span></p></li><li><p><span>Sensor size: Larger sensor size is better image (more light can be captured, less noise). Large is expensive. Large also means no need to enlarge photo.</span></p></li><li><p><span>Histogram: Bins that represent how much of the image is how bright (rightmost is maxed out, leftmost is no light). If there's a spike on the left that means that a lot of the image is dark, and vice versa.</span></p></li></ul></section></div><div class="firn-headline-section firn-headline-section-3"><h3 class="firn-headline firn-headline-3" id="color"><span class="firn-headline-text"><a href="#id:667e8b1b-de8a-4e31-b5e7-8c808ccca0cd">Color</a></span></h3><section><ul><li><p><span>Color spaces</span></p><ul><li><p><span>RGB: Red, green, and blue components on a scale from 0-255.</span></p></li><li><p><span>CMYK: Cyan, magenta, yellow, black components on a scale from 0-100.</span></p></li><li><p><span>HSV: Hue (color), saturation (vibrancy), value (darkness). Hue is a rainbow wrapped into a circle, so is 0-360 degrees. S and V are from 0 to 1.</span></p></li><li><p><span>LAB: Perception-based: scale of red-green and blue-yellow and perceptual brightness.</span></p></li></ul></li><li><p><strong><span>Additive/subtractive colors</span></strong><span>: in an </span><em><span>additive</span></em><span> space like RGB you start at black and adding more color brings you towards white, and in a </span><em><span>subtractive</span></em><span> space like CMYK you start at white and more colors darkens it towards black (not exactly, so K component).</span></p></li><li><p><strong><span>Color solids</span></strong><span>: map color scales to dimensions of a solid. RGB cube, HSL cylinder.</span></p></li><li><p><strong><span>Color temperature</span></strong><span>: temperature at which an ideal blackbody would emit that color. Blackbodies of different temperatures produce different spectrums, with high temp ones being spikier and bluer and low temp ones being flatter and redder. Human perception is very good at interpreting the true color of objects under tinted light, so cameras use shift color temperature (or "white balance") to attempt to match the colors to it.</span></p></li><li><p><strong><span>Color in film</span></strong><span>: Layers of material sensitive to specific colors: blue sensitive gets yellow, green-sensitive magenta, red-sensitive cyan. Negatives produced are the opposite colors.</span></p></li><li><p><strong><span>Color in digital</span></strong><span>: not every sensor gets all colors, instead use a grid with mostly green, some red, and some blue, and determine color value from neighbors (which assumes color is constant over small angular scales).</span></p></li></ul></section></div><div class="firn-headline-section firn-headline-section-1"><h1 class="firn-headline firn-headline-1" id="prism-dispersion"><span class="firn-headline-text"><span>Prism dispersion</span></span></h1><section><ul><li><p><span>Refracted internal beam forms a triangle with the prism (which has known angles), allowing calculation via</span></p></li><li><p><span>$\arcsin\left(\sin\left(90-\left(180 - \left(\sin^{-1}\left(\frac{\sin(x)}{n}\right)+60\right)\right)n\right)$</span></p></li><li><p><span>Literally just use Snell's Law ($\sin \theta_1 n_1 = \sin \theta_2 n_2$) and geometry.</span></p></li></ul></section></div><div class="firn-headline-section firn-headline-section-1"><h1 class="firn-headline firn-headline-1" id="aberration"><span class="firn-headline-text"><span>Aberration</span></span></h1><section><p><span>Ideally all rays from a point converge at a single image point - anything that stops this from happening is an </span><em><span>aberration</span></em><span>. Chromatic aberrations are due to the fact that lenses focus colors differently since its focal length is dependent on index of reflection (see Lensmaker's Eq) which varies w/ wavelength. There are a variety of other aberrations caused by slightly imparallel rays, lens defects, etc. Aberrations are counteracted by multi-lens systems.</span></p></section></div><div class="firn-headline-section firn-headline-section-1"><h1 class="firn-headline firn-headline-1" id="magnification"><span class="firn-headline-text"><span>Magnification</span></span></h1><section><ul><li><p><span>$h_i/h_o$ is </span><em><span>spatial</span></em><span> magnification</span></p></li><li><p><span>Ratio of image on aided to retina to unaided retina is </span><em><span>angular</span></em><span> magnification.</span></p><ul><li><p><span>This is equivalent to the powerful lens / weaker lens in a two lens system? I think?</span></p></li><li><p><span>Size of image in eye is directly proportional to angle subtended from object, so becomes unaided subtended angle $\alpha$ over aided subtended angle $\beta$.</span></p></li><li><p><span>$\alpha = \frac{h}{F_o}$ and $\beta = \frac{h}{F_e}$, where $h$ is height of internal real image, $F_e$ focal length of eyepiece, and $F_o$ focal length of objective lens. $M = \frac{\beta}{\alpha} = \frac{F_o}{F_e}$. Alternatively, this can be thought of as the lower power lens over the higher power lens (where </span><em><span>power</span></em><span> is the inverse of the focal length and measured in inv meters aka diopters).</span></p></li></ul></li></ul></section></div><div class="firn-headline-section firn-headline-section-1"><h1 class="firn-headline firn-headline-1" id="dof"><span class="firn-headline-text"><span>DoF</span></span></h1><section><ul><li><p><span>Choose an object of arbitary distance to focus at, set the $d_i$, and then for objects of different $d_o$ compare their $d_i$, set up similar triangles to get blur.</span></p></li></ul></section></div></div></div></article><div class="metapanel"><div class="metalabel">Contents</div><ol><li><a href="#color">Color</a></li><li><a href="#prism-dispersion">Prism dispersion</a></li><li><a href="#aberration">Aberration</a></li><li><a href="#magnification">Magnification</a></li><li><a href="#dof">DoF</a></li></ol><div class="metalabel">Backlinks</div></div></main></body></html>