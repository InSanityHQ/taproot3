<html><head><meta charset="utf-8" /><meta content="width=device-width, initial-scale=1.0" name="viewport" /><meta content="Huxley" name="author" /><meta content="A note on Taproot, a connected notes system." name="description" /><title>Ethical Concerns</title><link href="/static/css/firn_base.css" rel="stylesheet" /><link href="/static/css/prism.css" rel="stylesheet" /><link href="/static/css/global.css" rel="stylesheet" /><link href="/static/css/admonition.css" rel="stylesheet" /><script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/prism.min.js" type="text/javascript"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        'displayAlign': 'center',
        'displayIndent': '0em',
        'extensions': ['tex2jax.js'],
        'tex2jax': {
        'inlineMath': [ ['$','$'], ['\\(','\\)'] ],
        'processEscapes': true
        },
        'HTML-CSS': { scale: 100,
                        linebreaks: { automatic: 'false' },
                        webFont: 'TeX'
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: 'false' },
              font: 'TeX'},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: 'AMS'},
               MultLineWidth: '85%',
               TagSide: 'right',
               TagIndent: '.8em'
             }})</script></head><body><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/components/prism-core.min.js" type="text/javascript"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/plugins/autoloader/prism-autoloader.min.js" type="text/javascript"></script><script crossorigin=="anonymous" src="https://kit.fontawesome.com/76c5ce8bda.js"></script><div class="headerline"><a class="wordmark" href="https://taproot3.sanity.gq/" style="border:0">TR3</a></div><main><article class="content rss"><div class="preamble"><h1 class="title">Ethical Concerns</h1></div><div class="metamble"><span><span>Written by </span><span>Huxley</span></span></div><div class="notebody"><div><section><p><span>#flo #disorganized #incomplete</span></p><hr /></section><div class="firn-headline-section firn-headline-section-1"><h1 class="firn-headline firn-headline-1" id="can-we-get-back-to-coding"><span class="firn-headline-text"><span>Can we get back to coding</span></span></h1><section><p><span>please? yaow.</span></p><hr /><ul><li><p><span>Privacy</span></p><ul><li><p><span>Good ml requires lots of data, so inherent leads to violation</span></p></li><li><p><span>Also, algorythym predicts private things?</span></p><ul><li><p><span>Target example.</span></p></li></ul></li></ul></li><li><p><span>Bias</span></p><ul><li><blockquote><p><span>      Our model has bias built into them</span></p></blockquote><ul><li><p><span>ex. prop 25</span></p><ul><li><p><span>get rid of bail, and use ml to identify flight risks</span></p></li><li><p><span>has bias in the model due to a biased dataset</span></p></li></ul></li></ul></li><li><p><span>Input bias -> output bias</span></p></li></ul></li><li><p><span>Abuse and misuse</span></p><ul><li><p><span>Using ml in ways that are morally wrong</span></p><ul><li><p><span>Ex. Cambridge analytica</span></p><ul><li><p><span>Put up quizes, then sold data to companys which put targeted
        adds to swing votes.</span></p></li></ul></li></ul></li></ul></li><li><p><span>Model explanability</span></p><ul><li><p><span>Don't know how to explain results</span></p></li></ul></li><li><p><span>Responsibility</span></p><ul><li><p><span>Sold model to someone who used it for abusive use / it just breaks</span></p><ul><li><p><span>Who is at fault?</span></p><ul><li><p><span>Model builder? Data collector? Abuser?</span></p></li></ul></li><li><p><span>Large problem for things that are "literally life or death"</span></p><ul><li><p><span>Watson, what happens when it's wrong?</span></p></li></ul></li></ul></li></ul></li><li><p><span>Automation of labor</span></p><ul><li><p><span>Putting people out of jobs</span></p></li><li><p><span>More existential: what will people do? When ml does everything
    better than us</span></p></li><li><p><span>sudo-creative work is already being done</span></p></li></ul></li><li><p><span>Existential risk</span></p><ul><li><p><span>Essentially, terminator risk</span></p></li><li><p><span>Or, morality is not encoded into ml for task optimization</span></p><ul><li><p><span>ex. make a class happy,</span></p><ul><li><p><span>human: fun activity</span></p></li><li><p><span>ml: inject morphine</span></p></li></ul></li><li><p><span>Paperclip</span></p><ul><li><p><span>primary directive of producing paperclips</span></p></li><li><p><span>ignores morality</span></p></li></ul></li></ul></li></ul></li></ul></section></div></div></div></article><div class="metapanel"><div class="metalabel">Contents</div><ol><li><a href="#can-we-get-back-to-coding">Can we get back to coding</a></li></ol><div class="metalabel">Backlinks</div></div></main></body></html>